import streamlit as st
from google import genai # Ho·∫∑c: from google import gemini
from google.genai import types # Ho·∫∑c: from google.gemini import types
import os

# --- Thi·∫øt l·∫≠p API Key v√† M√¥ h√¨nh Gemini ---
# ƒê·∫£m b·∫£o b·∫°n ƒë√£ ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY ho·∫∑c s·ª≠ d·ª•ng st.secrets
# st.secrets["GEMINI_API_KEY"]
try:
    # L·∫•y API Key t·ª´ Streamlit secrets ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng
    api_key = os.environ.get("GEMINI_API_KEY") # ∆Øu ti√™n d√πng bi·∫øn m√¥i tr∆∞·ªùng khi deploy
    if not api_key:
        # Th·ª≠ l·∫•y t·ª´ st.secrets n·∫øu c√≥
        api_key = st.secrets["GEMINI_API_KEY"]

    if api_key:
        client = genai.Client(api_key=api_key) # Kh·ªüi t·∫°o Client
    else:
        st.error("‚ö†Ô∏è Vui l√≤ng cung c·∫•p GEMINI_API_KEY th√¥ng qua bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c st.secrets.")
        st.stop()
except Exception as e:
    st.error(f"‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o Gemini Client: {e}. Vui l√≤ng ki·ªÉm tra API Key.")
    st.stop()


# --- C·∫•u h√¨nh M√¥ h√¨nh ---
MODEL_NAME = "gemini-2.5-flash" # Ch·ªçn m√¥ h√¨nh ph√π h·ª£p

# --- Kh·ªüi t·∫°o Streamlit Chat (Gi·ªØ nguy√™n c√°c ƒëo·∫°n m√£ kh√°c) ---

st.title("ü§ñ ·ª®ng d·ª•ng Streamlit H·ªèi ƒê√°p v·ªõi Gemini")
# st.write("C√°c ƒëo·∫°n m√£ kh√°c c·ªßa ·ª©ng d·ª•ng n·∫±m ·ªü ƒë√¢y...")

# --- LOGIC KHUNG CHAT M·ªöI ---

# 1. Kh·ªüi t·∫°o L·ªãch s·ª≠ Chat trong Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Th√™m tin nh·∫Øn ch√†o m·ª´ng ban ƒë·∫ßu
    st.session_state.messages.append({"role": "model", "content": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI ƒë∆∞·ª£c cung c·∫•p b·ªüi Gemini. B·∫°n c·∫ßn t√¥i gi√∫p g√¨?"})

# 2. Kh·ªüi t·∫°o Phi√™n Chat (Chat Session)
# S·ª≠ d·ª•ng m·ªôt h√†m ƒë·ªÉ kh·ªüi t·∫°o ho·∫∑c l·∫•y phi√™n chat hi·ªán t·∫°i
@st.cache_resource
def get_chat_session():
    # Kh·ªüi t·∫°o m·ªôt phi√™n chat v·ªõi l·ªãch s·ª≠ ban ƒë·∫ßu (n·∫øu c√≥)
    # C·∫ßn chuy·ªÉn ƒë·ªãnh d·∫°ng l·ªãch s·ª≠ c·ªßa st.session_state sang ƒë·ªãnh d·∫°ng c·ªßa Gemini API
    history_for_gemini = [
        types.Content(role=msg["role"], parts=[types.Part.from_text(msg["content"])])
        for msg in st.session_state.messages
        if msg["role"] != "system" # B·ªè qua c√°c tin nh·∫Øn role "system" n·∫øu c√≥
    ]

    return client.chats.create(
        model=MODEL_NAME,
        history=history_for_gemini
    )

chat = get_chat_session()

# 3. Hi·ªÉn th·ªã L·ªãch s·ª≠ Chat
for message in st.session_state.messages:
    # B·ªè qua tin nh·∫Øn ch√†o m·ª´ng (role model ƒë·∫ßu ti√™n) khi hi·ªÉn th·ªã n·∫øu b·∫°n mu·ªën
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. X·ª≠ l√Ω Input c·ªßa Ng∆∞·ªùi d√πng
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o ƒë√¢y..."):
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
    with st.chat_message("user"):
        st.markdown(prompt)

    # G·ª≠i c√¢u h·ªèi ƒë·∫øn Gemini v√† hi·ªÉn th·ªã ph·∫£n h·ªìi
    with st.chat_message("model"):
        with st.spinner("Gemini ƒëang suy nghƒ©..."):
            try:
                # S·ª≠ d·ª•ng send_message ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh chat
                response = chat.send_message(prompt)
                full_response = response.text

                # Hi·ªÉn th·ªã ph·∫£n h·ªìi v√† th√™m v√†o l·ªãch s·ª≠
                st.markdown(full_response)
                st.session_state.messages.append({"role": "model", "content": full_response})

            except Exception as e:
                error_msg = f"ƒê√£ x·∫£y ra l·ªói khi g·ªçi Gemini API: {e}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "model", "content": error_msg})
