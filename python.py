import streamlit as st
from google import genai # Hoáº·c: from google import gemini
from google.genai import types # Hoáº·c: from google.gemini import types
import os

# --- Thiáº¿t láº­p API Key vÃ  MÃ´ hÃ¬nh Gemini ---
# Äáº£m báº£o báº¡n Ä‘Ã£ Ä‘áº·t biáº¿n mÃ´i trÆ°á»ng GEMINI_API_KEY hoáº·c sá»­ dá»¥ng st.secrets
# st.secrets["GEMINI_API_KEY"]
try:
    # Láº¥y API Key tá»« Streamlit secrets hoáº·c biáº¿n mÃ´i trÆ°á»ng
    api_key = os.environ.get("GEMINI_API_KEY") # Æ¯u tiÃªn dÃ¹ng biáº¿n mÃ´i trÆ°á»ng khi deploy
    if not api_key:
        # Thá»­ láº¥y tá»« st.secrets náº¿u cÃ³
        api_key = st.secrets["GEMINI_API_KEY"]

    if api_key:
        client = genai.Client(api_key=api_key) # Khá»Ÿi táº¡o Client
    else:
        st.error("âš ï¸ Vui lÃ²ng cung cáº¥p GEMINI_API_KEY thÃ´ng qua biáº¿n mÃ´i trÆ°á»ng hoáº·c st.secrets.")
        st.stop()
except Exception as e:
    st.error(f"âš ï¸ Lá»—i khi khá»Ÿi táº¡o Gemini Client: {e}. Vui lÃ²ng kiá»ƒm tra API Key.")
    st.stop()


# --- Cáº¥u hÃ¬nh MÃ´ hÃ¬nh ---
MODEL_NAME = "gemini-2.5-flash" # Chá»n mÃ´ hÃ¬nh phÃ¹ há»£p

# --- Khá»Ÿi táº¡o Streamlit Chat (Giá»¯ nguyÃªn cÃ¡c Ä‘oáº¡n mÃ£ khÃ¡c) ---

st.title("ğŸ¤– á»¨ng dá»¥ng Streamlit Há»i ÄÃ¡p vá»›i Gemini")
# st.write("CÃ¡c Ä‘oáº¡n mÃ£ khÃ¡c cá»§a á»©ng dá»¥ng náº±m á»Ÿ Ä‘Ã¢y...")

# --- LOGIC KHUNG CHAT Má»šI ---

# 1. Khá»Ÿi táº¡o Lá»‹ch sá»­ Chat trong Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ThÃªm tin nháº¯n chÃ o má»«ng ban Ä‘áº§u
    st.session_state.messages.append({"role": "model", "content": "Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Gemini. Báº¡n cáº§n tÃ´i giÃºp gÃ¬?"})

# 2. Khá»Ÿi táº¡o PhiÃªn Chat (Chat Session)
# Sá»­ dá»¥ng má»™t hÃ m Ä‘á»ƒ khá»Ÿi táº¡o hoáº·c láº¥y phiÃªn chat hiá»‡n táº¡i
@st.cache_resource
def get_chat_session():
    # Khá»Ÿi táº¡o má»™t phiÃªn chat vá»›i lá»‹ch sá»­ ban Ä‘áº§u (náº¿u cÃ³)
    # Cáº§n chuyá»ƒn Ä‘á»‹nh dáº¡ng lá»‹ch sá»­ cá»§a st.session_state sang Ä‘á»‹nh dáº¡ng cá»§a Gemini API
    history_for_gemini = [
        types.Content(role=msg["role"], parts=[types.Part.from_text(msg["content"])])
        for msg in st.session_state.messages
        if msg["role"] != "system" # Bá» qua cÃ¡c tin nháº¯n role "system" náº¿u cÃ³
    ]

    return client.chats.create(
        model=MODEL_NAME,
        history=history_for_gemini
    )

chat = get_chat_session()

# 3. Hiá»ƒn thá»‹ Lá»‹ch sá»­ Chat
for message in st.session_state.messages:
    # Bá» qua tin nháº¯n chÃ o má»«ng (role model Ä‘áº§u tiÃªn) khi hiá»ƒn thá»‹ náº¿u báº¡n muá»‘n
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. Xá»­ lÃ½ Input cá»§a NgÆ°á»i dÃ¹ng
if prompt := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n vÃ o Ä‘Ã¢y..."):
    # ThÃªm tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Hiá»ƒn thá»‹ tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gá»­i cÃ¢u há»i Ä‘áº¿n Gemini vÃ  hiá»ƒn thá»‹ pháº£n há»“i
    with st.chat_message("model"):
        with st.spinner("Gemini Ä‘ang suy nghÄ©..."):
            try:
                # Sá»­ dá»¥ng send_message Ä‘á»ƒ duy trÃ¬ ngá»¯ cáº£nh chat
                response = chat.send_message(prompt)
                full_response = response.text

                # Hiá»ƒn thá»‹ pháº£n há»“i vÃ  thÃªm vÃ o lá»‹ch sá»­
                st.markdown(full_response)
                st.session_state.messages.append({"role": "model", "content": full_response})

            except Exception as e:
                error_msg = f"ÄÃ£ xáº£y ra lá»—i khi gá»i Gemini API: {e}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "model", "content": error_msg})


# --- Káº¾T THÃšC LOGIC KHUNG CHAT ---
